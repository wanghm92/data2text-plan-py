{'accum_count': 1,
 'adagrad_accumulator_init': 0.1,
 'adam_beta1': 0.9,
 'adam_beta2': 0.999,
 'attn_hidden': 64,
 'batch_size': 5,
 'batch_type': 'sents',
 'bridge': False,
 'brnn': None,
 'brnn2': True,
 'brnn_merge': 'concat',
 'cnn_kernel_width': 3,
 'context_gate': None,
 'copy_attn': True,
 'copy_attn_force': False,
 'copy_loss_by_seqlength': False,
 'coverage_attn': False,
 'data': 'rotowire/bk/ratish/preprocess/roto',
 'dec_layers1': 1,
 'dec_layers2': 2,
 'decay_method': '',
 'decoder_type1': 'pointer',
 'decoder_type2': 'rnn',
 'dropout': 0.3,
 'enc_layers1': 1,
 'enc_layers2': 2,
 'encoder_type1': 'mean',
 'encoder_type2': 'brnn',
 'epochs': 25,
 'exp': '',
 'exp_host': '',
 'feat_merge': 'mlp',
 'feat_vec_exponent': 0.7,
 'feat_vec_size': 600,
 'fix_word_vecs_dec': False,
 'fix_word_vecs_enc': False,
 'global_attention': 'general',
 'gpuid': [0],
 'input_feed': 1,
 'label_smoothing': 0.0,
 'lambda_coverage': 1,
 'layers': -1,
 'learning_rate': 0.15,
 'learning_rate_decay': 0.97,
 'max_generator_batches': 32,
 'max_grad_norm': 5,
 'model_type': 'text',
 'normalization': 'sents',
 'optim': 'adagrad',
 'param_init': 0.1,
 'position_encoding': False,
 'pre_word_vecs_dec': None,
 'pre_word_vecs_enc': None,
 'report_every': 100,
 'reuse_copy_attn': True,
 'rnn_size': 600,
 'rnn_type': 'LSTM',
 'sample_rate': 16000,
 'save_model': 'rotowire/bk/ratish/gen_model/temp/roto',
 'seed': 1234,
 'share_decoder_embeddings': False,
 'share_embeddings': False,
 'src_word_vec_size': 600,
 'stage1': False,
 'start_checkpoint_at': 4,
 'start_decay_at': 4,
 'start_epoch': 1,
 'tensorboard': False,
 'tensorboard_log_dir': 'runs/onmt',
 'tgt_word_vec_size': 600,
 'train_from': '',
 'truncated_decoder': 100,
 'valid_batch_size': 5,
 'warmup_steps': 4000,
 'window_size': 0.02,
 'word_vec_size': 600}
Experiment 22-4.4 using attn_dim of 64
Loading train dataset from rotowire/bk/ratish/preprocess/roto.train.1.pt, number of examples: 3371
 * vocabulary size. source1 = 1164; target1 = 391, source2 = 956; target2 = 9902
 * src feature 0 size = 702
 * src feature 1 size = 39
 * src feature 2 size = 4
Building model...
Intializing model parameters.
Intializing model parameters.
NMTModel(
  (encoder): MeanEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(1164, 600, padding_idx=1)
          (1): Embedding(702, 600, padding_idx=1)
          (2): Embedding(39, 600, padding_idx=1)
          (3): Embedding(4, 600, padding_idx=1)
        )
        (mlp): Sequential(
          (0): Linear(in_features=2400, out_features=600, bias=True)
          (1): ReLU()
        )
      )
    )
    (dropout): Dropout(p=0.3)
    (attn): GlobalSelfAttention(
      (transform_in): Sequential(
        (0): Linear(in_features=600, out_features=64, bias=True)
        (1): ELU(alpha=0.1)
      )
      (linear_in): Linear(in_features=64, out_features=64, bias=False)
      (linear_out): Linear(in_features=1200, out_features=600, bias=False)
      (sm): Softmax()
      (tanh): Tanh()
      (dropout): Dropout(p=0.3)
    )
  )
  (decoder): PointerRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(391, 600, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3)
    (rnn): LSTM(600, 600, dropout=0.3)
    (attn): PointerAttention(
      (linear_in): Linear(in_features=600, out_features=600, bias=False)
      (sm): LogSoftmax()
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=600, out_features=391, bias=True)
    (1): LogSoftmax()
  )
)
NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(956, 600, padding_idx=1)
          (1): Embedding(547, 600, padding_idx=1)
          (2): Embedding(33, 600, padding_idx=1)
          (3): Embedding(4, 600, padding_idx=1)
        )
        (mlp): Sequential(
          (0): Linear(in_features=2400, out_features=600, bias=True)
          (1): ReLU()
        )
      )
    )
    (rnn): LSTM(600, 300, num_layers=2, dropout=0.3, bidirectional=True)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(9902, 600, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3)
      (layers): ModuleList(
        (0): LSTMCell(1200, 600)
        (1): LSTMCell(600, 600)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=600, out_features=600, bias=False)
      (linear_out): Linear(in_features=1200, out_features=600, bias=False)
      (sm): Softmax()
      (tanh): Tanh()
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=600, out_features=9902, bias=True)
    (linear_copy): Linear(in_features=600, out_features=1, bias=True)
  )
)
* number of parameters: 7062951
('encoder: ', 3348560)
('decoder: ', 3714391)
* number of parameters: 26876703
('encoder: ', 6694200)
('decoder: ', 20182503)
